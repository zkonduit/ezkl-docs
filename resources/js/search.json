[[{"i":"what-is-ezkl","l":"What is EZKL?"},{"l":"EZKL makes zero-knowledge easier","p":["ezkl takes a high-level description of your program and sets up a zero-knowledge prover and verifier. Our focus is on programs that are expressed as pytorch AI/ML models and other computational graphs. After setup, the prover can prove statements such as the following.","\"I ran this publicly available neural network on some private data and it produced this output\"","\"I ran my private neural network on some public data and it produced this output\"","\"I correctly ran this publicly available neural network on some public data and it produced this output\"","These proofs can be trusted by anyone with a copy of the verifier, and verified directly on Ethereum and compatible chains. ezkl can be used directly from Python; see this colab notebook and the python bindings docs. It can also be used from the command line.","ezkl can prove an MNIST-sized inference in less than a second and under 180mb of memory and verify it on the Ethereum Virtual Machine (or on the command line, or in the browser using wasm).","You can install the Python version with pip install ezkl.","ezkl can be used to move large and complex computations off-chain in a way that is easy to program (you can write your own functions in Python) and manage. You are not limited to a pre-defined set of functions, there is no limit on input size (using hashing), and there is no centralized sequencer.","For more details on how to use ezkl, we invite you to explore the docs and check out the repo, especially the notebooks."]},{"l":"Zero-knowledge proofs","p":["A zero-knowledge proof is a programmable digital signature. In a traditional digital signature scheme, we have a secret key, a public message, and a signature algorithm that was set up in advance and everyone knows. These are applied to the inputs to produce a signature and a public message, which is then verified by a counterparty (such as a blockchain). A zero-knowledge proof allows us to replace the secret key and public message with arbitrary private and public inputs, and it lets us run any program we like on them, not just a fixed signature algorithm.","Just as with a digital signature, there are three parties: one to define the setup, one to prove, and one to verify."]},{"l":"The life cycle of a proof","p":["There are three steps in the life of an ezkl proof: Setup, Prove, and Verify. Each step is generally performed by a different party."]},{"l":"Setup","p":["Setup is invoked with ezkl setup at the cli or ezkl.setup() in Python. It defines what constitutes a proof and how that proof will be verified, setting the rules of the game. Setup is performed by the application developer, who then deploys the resulting artifacts to production.","The inputs to setup are:","the model (as an onnx file)","the structured reference string which is a common, public piece of cryptographic data shared among proof setups of the same size","various flags, settings, and options for tuning and added functionality","The outputs of setup are:","the proving key","the verification key, and","the circuit settings: serialized flags, settings, and options, and a few numbers that describe the shape of the resulting circuit.","Before setup can run, the settings need to be generated with gen-settings and optionally calibrate-settings, and the model must be compiled."]},{"l":"Prove","p":["Prove, invoked with ezkl prove at the cli or ezkl.prove() in Python, is called by the prover, often on the client. The prover is making a claim that it knows some inputs (which might include model parameters), such that when the model (chosen during setup) is run on them, produces certain outputs. The prove command computes a cryptographic proof of that claim, which can then be believed by any verifier.","The inputs to prove are:","the witness data for the claim: an (input, output) pair (x,y) such that model(input) = output (this pair can be produced from x using the gen-witness command)","the model (as a compiled model file, made from an onnx file)","the proving key","the structured reference string, and","the circuit settings.","The outputs of prove are:","the proof file."]},{"l":"Verify","p":["ezkl can produce an EVM verifier contract which takes only the proof as input, and this is the normal use case.","Verification can also be invoked with ezkl verify at the cli, ezkl.verify() in Python, or with WASM. It checks the correctness of the cryptographic proof produced by the prover.","The inputs to (non-EVM) verify are:","the proof file","the verification key","the circuit settings, and","the structured reference string"]},{"i":"contributing","l":"Contributing \uD83C\uDF0E","p":["If you're interested in contributing and are unsure where to start, reach out to one of the maintainers on our Telegram group or our Discord.","More broadly:","Feel free to open up a discussion topic to ask questions.","See currently open issues for ideas on how to contribute.","For PRs we use the conventional commits naming convention."]}],[{"l":"Getting Started"},{"l":"Installing EZKL","p":["To use ezkl in Python, just pip install ezkl. You will generally also need onnx installed if you are exporting models, and Pytorch, Tensorflow, or similar if you are creating models.","ezkl uses your system solc Solidity compiler, so you may need to tweak it using svm-rs or solc-select, particularly if you are targeting a specific hardfork.","To use the cli, download a release binary from GitHub. If you want the latest build, you can also install from source."]},{"i":"building-from-source","l":"Building from source \uD83D\uDD28","p":["Ezkl is built in rust. First install rust, then download the repo and enter the directory","After which you may build and install the library","If you want to build manually with cargo build, be sure to use the release flag as the debug build will result in slow proofs","Note: To render your model circuits, you'll need to compile ezkl with the render feature ( cargo build --features render --bin ezkl). This enables the render-circuit command which can create .png representations of the compiled circuits. You'll also need to install the libexpat1-dev and libfreetype6-dev libraries on Debian systems (there are equivalents for MacOS as well)."]},{"i":"rust-docs","l":"Rust docs \uD83D\uDCD6","p":["Use cargo doc --open to compile and open the Rust documentation for ezkl in your default browser."]}],[{"l":"Command Line Interface","p":["The ezkl cli provides a simple interface to load .onnx files, which represent graphs of operations (such as neural networks), convert them, and run a proof."]},{"i":"cli-tutorial","l":"CLI tutorial \uD83D\uDC7E","p":["You can easily create an .onnx file using pytorch. For samples of Onnx files see here. To see how to generate Onnx files using python, check out the notebooks.. You'll also need an input.json file with sample inputs and outputs of your model.","Sample onnx files are also available in the repo ."]},{"l":"Initializing the project","p":["To generate a proof on one of the examples, first install ezkl Command Line Interface","Put a model file ( network.onnx) and input file ( input.json) into your working directory, e.g. with something like:","To display ezkl's understanding of the model, run:"]},{"l":"Setting circuit parameters","p":["Our circuit is configured with the settings.json file. This is created with the gen-settings command.","This will produce a settings.json file you can use for your circuit. However, you can fine-tune your circuit to optimize for accuracy or CPU/memory usage with the calibrate-settings command:","In this example, we set the --target to \"resources\" so that we can optimize for CPU and memory usage. The other option is \"accuracy\", which optimizes for accuracy given the fixed point representation of the input model. Our circuit parameters are generated, then saved to settings.json. You can pass a --settings-path to read from an existing settings file, and only modify the parts changed by calibration (e.g. leaving visibility or tolerance unchanged). You can customize this file and even change the way it is generated. Learn more about gen-settings and calibrate-settings in the Commands section.","Download the appropriate SRS:"]},{"l":"Compiling the model","p":["From the onnx file, we will create a .ezkl file that uses the settings to convert the onnx model to a format ready for proving."]},{"l":"Creating the circuit","p":["Now, we use setup to create a proving and verifying key for our circuit, using the SRS, our circuit settings, and the .onnx file.","This creates the verification key, proving key, and circuit settings in the locations you specify.","Note: You can view the options associated to a subcommand such as setup by typing ezkl setup with no parameters. If you provide some but not all required parameters, ezkl will tell you what else it needs."]},{"l":"Making a proof","p":["First we generate a witness file.","Next we will generate a proof that the model was correctly run on private inputs (this is the default setting). It then outputs the resulting proof at the path specfifed by --proof-path."]},{"l":"Verification","p":["We can then verify our generated proof with the verify command:"]},{"l":"All together"}],[{"l":"Commands"},{"l":"ezkl Commands","p":["Here is some more detail on ezkl commands."]},{"l":"Getting an SRS","p":["ezkl uses KZG commitments, which in turn require a structured reference string (SRS). You can download a KZG structured reference string with (for example) 17 rows as follows.","This sets up a SRS that the prover can use to commit and the verifier can use to evaluate in a file called 17.srs.","Note: ezkl has a command gen-srs to generate an SRS for testing purposes when bandwidth is scarce. The SRS generated by gen-srs is not meant to be used in production.","Note: Downsizing an SRS is time consuming, so if you obtain a logrows=20 SRS and the circuit uses logrows=17, the prove command will spend most of its time downsizing your 20.srs from 20 to 17. Once you know the logrows you need, use a file of that size for max speed."]},{"l":"Generate Settings","p":["For ezkl to compute a snark, it needs some settings to determine how to create the circuit. You can create settings with the gen-settings command.","For example, this is the file generated from our CLI tutorial example:","By default the settings file will be called settings.json.","settings.json:","Let's say our circuit was much larger; we need to bump logrows to 23. We can add a flag to our original command to specifiy this (using -O to give the output a different name):","This produces circuitK23.json: which is the same as the settings.json above, but with logrows now 23. You can do this for any other parameter for custom circuits. The .json file can also be manually edited to tweak the choices."]},{"l":"Calibrate Settings","p":["There are a lot of adjustable knobs (such as bits, scale, and logrows) in ezkl that let you trade off between prover and verifier resources, accuracy, and control other parts of the zkp setup. While you are free to choose these manually with cli parameters passed to gen-settings, we recommend fine-tuning with the automatic calibration provided by the calibrate-settings command. This modifies your settings.json file with a suggested choice of circuit parameters:","You can also set the --target to \"accuracy\" if you want to optimize for numerical accuracy rather than CPU and memory performance. The default is set to \"resources\". The largest tradeoff for these two is in the size of logrows and scale. With a higher scale, floating point numbers are interpreted more accurately. With a smaller logrows, a smaller, less memory-intensive circuit is generated.","For example, after running the same command with --target set to accuracy, we get a larger value for scale amongst other changes:","settings.json:","Note: You can still use the generic RunArgs for mock and gen-witness(e.g. ezkl mock --logrows=22 --bits=21 rather than ezkl mock --settings-path circuit.json). However, --settings-path takes priority."]},{"l":"Compile circuit","p":["This converts and freezes the onnx file to what ezkl will actually prove against, incorporating the settings, quantizing, etc."]},{"l":"Setup","p":["Along with our SRS and circuit parameters, we need two other elements to generate a proof: a proving key and a verifying key. You will get both by running ezkl's setup command. We need our proving key to generate proofs; we need our verifying key to verify proofs from the corresponding proving key, or to generate an EVM verifier.","Run this command to set up your proving and verifying keys:","You should now have files called vk.key and pk.key in the root of your project. You can also specify different paths for these outputs with --vk-path=altvk.key --pk-path=altpk.key"]},{"l":"Generate witness","p":["Now we take the input data, quantize it, and run it through the quantized model, performing any hashing or encryption, to obtain the input and output that we will be proving.","The default output file is witness.json."]},{"l":"Prove","p":["Now that we have all the parameters, we can generate our proof.","In a typical zk application, the proof will be generated by or on behalf of the client, then verified on a blockchain or server. ezkl provides WASM bindings for prove that you can use to generate proofs in-browser.","Here is the command for generating a proof from the cli:","This will create a proof file called model.proof that anyone can later use to verify your model was run correctly on the input."]},{"l":"Verify","p":["Verification can be done from the CLI, in WASM, or on a blockchain. Verification will require the commitment scheme parameters, the circuit parameters, the verifying key, and, of course, the proof. When verifying with a smart contract, however, the verifying key and circuit/commitment params are baked into the smart contract; this means only the public parameters will be passed as calldata along with the proof. The command for verifying from the CLI is:","This will return whether your proof has successfully verified or not. Refer to Verifying On-Chain section to verify with an EVM smart contract.","Commands","Note that these are not the only operations that can be performed by ezkl. You can also run a Mock proof to see if a proof will verify, or run the Table command to see a table of all your onnx operations that your SNARK will consist of. The table command is helpful in determining if ezkl knows how to snark your model. You can also run Fuzz to fuzz test your SNARK on random inputs. Even our EVM commands can take in RunArgs to specify how an evm verifier will be created. Let's look into the rest of these in detail."]},{"l":"Mock","p":["When you're testing a model, you may not want to run setup and prove with each iteration. ezkl provides a simple alternative with mock, where you can convert your model to constraints and run the inputs tosee if a proof can be generated. This saves time when testing new iterations of models with potential issues. Here is the command for mock:","Mock is basically checking that constraints that your model has been translated into are satisfied, without doing any of the subsequent cryptographic heavy lifting to produce a proof."]},{"i":"generate-witness-1","l":"Generate Witness","p":["The gen-witness function generates a witness for a given model and input data for a neural net or computational graph. A witness in the context of Zero Knowledge Proofs is a computational trace that allows a proof to be generated. The gen-witness function doesn't record all the intermediate values of the trace (such as the activations of inner layers in a neural network), but does write the final outputs of your neural network or computation graph in a form that is usable in the prove command, and human readable.","The function has additional configurable settings, including an ONNX model file path, an input data file path, an output file path, an optional scale, and an optional batch size. More details on the optional scale and optional batch size can be found in RunArgs."]},{"l":"Table","p":["ezkl's table command enables users to get their model's operations, inputs, and outputs in an intuitive format. Calling this command:","will produce a table that looks like:","You can use table with your model to know exactly which operations your model uses. If the operation is unsupported, you may see an Unknown in the table, and get a warning. This means the op isn't available in ezkl, and you should file an issue to request its implementation."]},{"l":"Render","p":["halo2 provides a service you can use to render a .png of your circuit layout, which can be useful in debugging. First install the binaries with the render feature enabled:","Then, run this command:","This will render our circuit as a file named render.png in our examples/onnx/1l_sigmoid directory.","image-20230608155046296","In this image,","Pink columns represent advice values","White columns represent instance values","Purple/blue columns represent fixed values","Green areas represent regions in our circuit"]},{"l":"Aggregate","p":["This step is described briefly in the Verifying On-Chain section. Here, we'll describe aggregate with more detail.","We can aggregate multiple proofs into one with the aggregate command. Let's make two new circuits: one that produces a proof called model.proof and another that produces a proof called model1.proof. In aggregation, we want to use a large circuit because we're dealing with multiple proofs. Let's set up a SRS of size k=23:","Now, let's say we want to aggregate a conv circuit and a relu circuit. We can set up the parameters for these different circuits with gen-circuit-params. For the sake of the example, let's set one to optimize for accuracy and another to optimize for resources:","and for RELU:","Now, we can create our proof keys with setup(Note: be sure to use the same KZG parameters for all the circuits you plan to aggregate):","We then prove them.","Setup the aggregation:","Now, we can aggregate the proofs:","This creates one proof that simultaneously proves both our conv and relu circuits as long as we pass both proofs and verifying keys in. The bad news is that computing an aggregation takes a lot of memory and time right now; this proof will probably take about two to five minutes depending on your machine."]},{"l":"VerifyAggr","p":["Now, we can verify our aggregated proof with:","This should return verified: true. You can learn more about aggregation here."]},{"l":"Fuzz","p":["You can learn more about fuzz in the Security section under EZKL Security Tooling."]}],[{"l":"RunArgs","p":["RunArgs are the fine-tuning parameters that give you more control over various aspects of ezkl. The majority of them have default values, so you typically don't see them in our basic instructions. They include:","Tolerance: -T| --tolerance","Scale: -S| --scale","Bits: -B| --bits","Logrows: -K| --logrows","Batch Size: --batch-size","Input Visibility: --input-visibility","Output Visibility: --output-visibility","Param Visibility: --param-visibility","Allocated Constraints: --allocated-constraints","they can be edited in the settings file, or passed as arguments to ezkl gen-settings."]},{"l":"Tolerance","p":["We need to quantize to represent the model using the finite field of our proof system, and this can introduce numerical error. You might want to explictly tolerate a small range of values in your output when verifying. A value of 1.0 is 1% tolerance."]},{"l":"Scale","p":["ezkl quantizes a floting point value to a fixed point value by multiplying by 2^{scale} and rounding. Then the numerator is stored. The default scale is 7. When two numerators of scale 7 are mutiplied, you get a number of scale 14. Scale can be adjusted with -S or --scale:"]},{"l":"Bits","p":["Bits is the number of bits used in ezkl's lookup tables for nonlinearities. The default is 16. We can adjust it with the -B or --bits flag.","Scale and bits are related. Typically we want bits to be twice scale, plus a margin of error (of perhaps 2 or 3), since two scale 7 numbers multiplied become scale 14, and then adding several of them we get to an even larger scale. That's why the default bits is twice the default scale plus 2. ezkl will give some warnings and suggestions if your scale and bits are off. Or just use calibrate-settings."]},{"l":"Logrows","p":["The logrows argument is the base 2 logarithm of the number of rows that are in our halo2 circuit. The default is 17. It cannot exceed the value of k in our structured reference string. You can read more about SRS in the first part of the Commands section. Bits must be at most one less than logrows (e.g. 16 when logrows is 17)."]},{"l":"Batch Size","p":["Perhaps you want to prove that a model was run on a batch of data rather than a single input. You can do this with the --batch-size flag (default is 1)."]},{"l":"Input Visibility","p":["Set this flag to public with --public-inputs=public(default private) if you want your inputs to be public instance variables in the halo2 circuit. Set it to hashed if you want the hash of your inputs to be public (with Poseidon). This can be useful for proving the validity or provenance of input data without necessarily making it public."]},{"l":"Output Visibility","p":["Set this flag to private with --public-outputs=private(default public) if you want your outputs to be private variables in the circuit. By default, outputs are public. You can also set this to hashed if you want your outputs hashed."]},{"l":"Param Visibility","p":["Set this flag to public(default private) with --public-params=public if you want your circuit parameters to be public. You can also hash these by using hashed."]},{"l":"Strategy","p":["In the Commands section, we used an example of proof aggregation to aggregate two proofs into one. You'll notice that the --strategy we used is called accum. The other option for --strategy is single(the default). These are used to specify the proving strategy. If we are proving a single circuit, we can leave this alone. If we are proving with aggregate, use the accum strategy."]}],[{"l":"Verifying On-Chain"},{"i":"verifying-with-the-evm-","l":"Verifying with the EVM â—Š","p":["To verify on-chain, generate a verifier smart contract after performing setup.","You can use the example from Commands, or create it by copying over a network and input file (assuming the ezkl repo is in your home directory):","then create the setup","Now we use this setup to create an EVM verifier, which would be deployed on-chain.","Note that the .sol file above can be deployed and composed with other Solidity contracts, via a verify() function."]},{"l":"Aggregation","p":["Note: this is an advanced technique, very resource-intensive, and chances are you don't want to use this; if you are having trouble with proof size, first try asking about your problem in Telegram or Discord.","The above pipeline can also be run using proof aggregation to reduce the final proof size and the size and execution cost of the on-chain verifier. A sample pipeline for doing so would be as follows.","Grab a smaller model.","Set up the first proof.","Setup the aggregate proof.","Also note that this may require a local solc installation. You can follow the SolidityLang instructions linked above, or you can use svm-rs to install solc. Here's how:","Install svm-rs:","Install a recent Solidity version (we use 0.8.20 in our implementation):","Verify your Solidity version:"]}],[{"i":"visibility-what-is-private","l":"Visibility: What is Private?"},{"l":"Visibility","p":["In ezkl there are four choices for Visibility: private, public, hashed, or encrypted, and three parts to chose these for: the model input, the model weights, and the model output (for 64 possible choices). The default setting is private input, public output, and private weights.","Visibility is controlled in the circuit settings ( settings.json file), and is determined at setup time.","The question of what is private is very much related to the question of what we are proving. These questions tend to be a bit subtle and are really about designing the overall cryptosystem, of which your ezkl proof is a part. We provide these options to enable many different constructions. It can take some thought to determine which is right for your use case.","At a high level, mark those things private that you want to be secret to the prover, and allow the prover to change freely. Mark things public if you want them to be baked into the setup, and generally available (although see the comments about weight visibility below). Setting a part to hashed is a way to commit to it, and also a way to build bridges between proofs, making sure that a piece of data (input, weights, or output) is the same in multiple proofs. Hashed parts are also useful to reduce calldata size for smart contracts, and to allow something to be signed. Finally making a part encrypted proves encryption inside the circuit, which is useful for some constructions such as marketplaces with escrow contracts.","Note that the proof file contains both the instance data (e.g. a hash of the model input and the actual output of the model) and the bytes of the cryptographic proof. These parts (instance data, proof bytes) are analogous to the message hash and signature in a digital signature."]},{"i":"data-provenance-signatures-and-linking-data","l":"Data provenance, signatures, and linking data","p":["A digital signature is a kind of zero knowledge proof. Ezkl can prove that a certain model says an image contains a cat, but you also have to think about whether that image is real (if that is important for your application). One technique to solve this data provenance problem is to use hashed visibility for the input image, and have a data source which separately signs the hash. Then the verifier can check the signature separately.","Putting it together, you would have two proofs. One, that Alice signed the (hash of the) image, using any signature algorithm on the Poseidon hash of the image. This can be computed and verified outside ezkl. Two, that the image with the given Poseidon hash contains a picture of a cat.","Then a verifier or verifier contract checks both the signature and the ezkl proof, and since the hash is the same, can be confident that the signature and the proof are \"talking about\" the same image."]},{"l":"Weight visibility","p":["When a model's weights are marked public, the weights are fixed at setup (circuit definition time). These weights are extractable from the proving key or the onnx file, but they can be kept private from the verifier as they are not part of the verifying key, proof, settings, or srs. Proofs can only be produced against the specific weights used at setup, so the verifier itself serves as a kind of implicit commitment to the weights. If you want to make an explicit commitment to the weights, for example to tie them to another model or sign them, use the hashed Visibility.","Private: The weights are private to the prover, and can be chosen freely by the prover.","Public: The weights are fixed by the setup, visible in the proving key, but not visible in the verifying key or verifier (although be aware of dictionary attacks).","Hashed: The weights are private, but the hash of the weights is in the proof file, preventing the prover from changing the weights.","Encrypted: The encrypted weights are in the proof file, and part of the proof is that this encryption is correct."]},{"l":"Input visibility","p":["Private: The input is private to the prover, and can be chosen freely by the prover.","Public: The input is part of the proof file, shared with the verifier.","Hashed: The input is not sent in the proof file, but a Poseidon hash of the input is sent instead. The input is chosen by the prover, but it has to match the hash. The verifier cannot determine the input from the hash alone (although beware of dictionary attacks).","Encrypted: The proof contains the encryption of the input, and part of the proof is that this encryption is correct."]},{"l":"Output visibility","p":["Private: The model output is private to the prover, and can be chosen freely by the prover.","Public: The model output is part of the proof file, shared with the verifier.","Hashed: The model output is not sent in the proof file, but a Poseidon hash of the output is sent instead. The verifier cannot determine the output from the hash alone (although beware of dictionary attacks).","Encrypted: The proof contains the encryption of the output, and part of the proof is that this encryption is correct."]},{"l":"Visibility Examples","p":["This section can safely be skipped but might provide more clarity on some common options for visibility. Consider a function f which given inputs x,y and weight c computes f(x,y) = cx+y.","Notice that weights \" c\" are different from the inputs x,y and output z. Weights are defined as part of the model (and will appear in the onnx).","Suppose we set input public, weights fixed (\"public\"), and output public. This means that c will be baked into the verifier and cannot be changed for this verifier. The witness data that will become part of the proof is (x,y,z). The prover is proving that cx+y = z, and the verifier sees x,y, and z, but not c. The setter-upper and the prover know c.","If we set input private, weights fixed (\"public\"), and output public, the witness data in the proof is (z). The prover is proving that it knows secret x,y such that cx+y = z. The setter-upper and the prover know c; the prover knows x,y; the verifier learns only z.","If we set input private, weights private, and output public, the witness data in the proof is (z). The prover is proving that it knows secret x,y,c such that cx+y = z(practically the prover might set c by changing a provided onnx file). The setter-upper does not know c, the prover knows c,x,y. The verifier learns only z.","If we set input private, weights hashed ( h = H(c)), and output public, the witness data in the proof is (h,z). The prover is proving that it knows secret x,y,c such that cx+y = z and h=H(c). The setter-upper does not know c, the prover knows c,x,y. The verifier learns only z and h. However, if h was previously committed to, the prover can no longer freely choose the weight c.","Hashed weights and fixed (\"public\") weights are similar in that they both constrain the weights that the prover can use. They differ in that fixed weights bake the weights into the circuit at setup, whereas hashed weights can be determined at proof time. One consequence is that for fixed weights, to change the weights a new verifier would need to be deployed, whereas for hashed weights we could simply require a different hash target. However, we pay a performance penalty for the flexiblity of using the \"dynamic\" hashed weights rather than the \"compiled\" fixed weights."]}],[{"l":"Python bindings"},{"l":"using ezkl from Python","p":["lets you use ezkl directly from Python. Here is a colab notebook that shows how to produce and verify a proof from Python.","When installing ezkl with pip, you may want to use a virtualenv. Some virtualenv management solutions for python includes venv, pipenv, conda, and poetry."]},{"l":"development","p":["Python bindings are built for ezkl using PyO3 and Maturin.","To test the development Python bindings you will need to install Python3.","Note, ezkl is only supported for Python=3.7, this installs the pyezkl build which contains Python specific functions that the Rust bindings on the main ezkl repository do not implement."]},{"l":"2. Install solc-select or svm-rs","p":["To run solidity and evm related functionality make sure to have solc available in your environment. We will need solc = 0.8.20, otherwise contracts will fail to compile. Otherwise, you are likely to encounter errors when dealing with solidity and evm related functionality that is used within ezkl.","It is recommended that you use solc-select if you prefer a python based management solution or svm if you prefer a rust based management solution. With a solidity version manager you are then able to change solidity versions in your environment easily."]},{"l":"3. Try out EZKL Examples in the repository with a Jupyter Notebook","p":["Clone the pyezkl repository.","Install jupyter and start the jupyter notebook","Navigate to the ezkl_demo.ipynb file which is located in the examples folder. It contains a minimal setup for running ezkl within python."]},{"l":"Developmental python bindings","p":["Setting up the development python bindings can be an involved process."]},{"l":"ezkl repository","p":["In the event that you may want to use the developmental bindings on the main ezkl repository, you can clone and build the main ezkl repository written in rust instead.","It's recommended that you set up a separate virtual environment for this.","Ensure that rust is installed in your local environment, this is needed by maturin/pyo3 to build the project.","Change the default toolchain to the nightly version as this is needed by some of the libraries used.","After which, you should be able to build via maturin build. This will build ezkl_lib not ezkl. ezkl_lib only includes the basic rust bindings without other Python functionality.","Once the build is complete, you will be able to find the built wheels within target/wheels. If your build is successful you should find a .whl file in the folder","Example:"]},{"l":"pyezkl repository","p":["If you would like to then use the development version of pyezkl with the developmental bindings at ezkl, you will need to setup pyezkl too.","Clone the pyezkl repository in a separate directory if you haven't done so already.","We will use poetry for the pyezkl repository. Install poetry by following the instructions provided.","You will also need to deactivate any existing virtualenv.","Once that is done setup the repository with poetry.","Navigate to the ezkl repository and install the wheel that you have built.","This will install the developmental ezkl_lib into the poetry environment. After which, you should be able to build the developmental ezkl library from the pyezkl repository.","If successful, you should be able to run python in your poetry environment and call the functions."]},{"l":"API Reference","p":["This reference details function, modules, and objects included in both ezkl and ezkl_lib. Note that ezkl is a superset of ezkl_lib so functions contained within ezkl_lib will be contained in ezkl."]},{"l":"ezkl"},{"l":"Utilities"},{"l":"export","p":["`","An ONNX file containing the exported model. The name of the file is specified by the onnx_filename argument. A JSON file containing a sample input for the model. The name of the file is specified by the input_filename argument.","Description The export function is designed to export a PyTorch model in ONNX format for further use in different environments without Python dependencies. It also saves a sample input in JSON format. The function supports models with single input and output.","Example","input_array (optional): This is a tensor that you can pass in if you want to specify the exact values of the input tensor. This should be a NumPy ndarray or something that can be converted into one (like a list or tuple of numbers). This argument is required if input_shape is not provided.","input_filename (optional): This is the name of the JSON file that will be generated containing a sample input for the model. The default value is \"input.json\".","input_shape (optional): This is a list of integers specifying the shape of the input tensor that the model expects. For example, for a 2D image, this might be [3, 224, 224] for three color channels (RGB) each of 224x224 pixels. This argument is required if input_array is not provided.","Notes The torch.onnx.export function is used to convert the PyTorch model to ONNX format. The function requires an example input tensor, which is used to run a forward pass of the model. This is needed because the ONNX exporter needs to know the shapes and data types of the tensors that flow through the model.","onnx_filename (optional): This is the name of the ONNX file that will be generated. The default value is \"network.onnx\".","Parameters torch_model (required): This is the PyTorch model you want to export. It should be an instance of a class that inherits from torch.nn.Module.","Returns The function does not have a return value. However, it writes two files to the disk:","run_calibrate_settings (optional): This is the boolean flag indicating whether calibrate_settings will be called prior to calling gen_witness. For more information about calibrate_settings visit Commands. The default value is True.","run_gen_witness (optional): This is a boolean flag indicating whether the gen_witness. step will be called prior to export. For more information about `gen_witness visit Commands. The default value is True.","settings_filename (optional): This is the name of JSON settings file that is generated by calling the calibrate function. The calibrate function is called by default in the export function. The default value is \"settings.json\".","The exported ONNX model includes the weights of the trained model and also the network architecture. This means that the model can be used for inference in an environment where PyTorch is not installed.","The ezkl_lib.forward function is used for the forward operation to quantize inputs, there may be quantization errors associated with the quantization. Error metric functions can be used to compare the performance before and after quantization.","The function raises an error if neither input_shape nor input_array are provided, or if both are provided but input_shape doesn't match the shape of input_array."]},{"l":"ezkl_lib"},{"l":"Command Bindings"},{"l":"PyRunArgs","p":["allocated_constraints: This is an optional field that may contain a usize value representing the number of allocated constraints.","batch_size: This is a 32-bit unsigned integer that specifies the batch size for certain operations.","bits: This is a usize type and denotes the bit length for the snark.","Description","Fields","Fields marked with the #[pyo3(get, set)] attribute can be accessed (read or modified) directly from Python.","logrows: This is a 32-bit unsigned integer. This corresponds to the K value used in generating the SRS (Structured Reference String). You can obtain generated SRS from the powers of tau repository or call the gen_srs function for development use.","Methods The PyRunArgs struct has a new method that provides default instantiation. It initializes the fields with default values.","Notes For integer fields, you are able to use default Python integers.","pack_base: This is a 32-bit unsigned integer. This value refers to the packing base value to be used in the snark.","public_inputs: This is a boolean flag indicating whether inputs are public.","public_outputs: This is a boolean flag indicating whether outputs are public.","public_params: This is a boolean flag indicating whether parameters are public.","scale: This is a 32-bit unsigned integer which could be used to scale computation.","The PyRunArgs struct is a Python-friendly data structure that provides a set of arguments required to perform certain operations in a Rust environment. The structure is defined using the pyclass macro from the pyo3 library which makes it compatible with Python via PyO3/Maturin. The fields of PyRunArgs are accessible from Python, and can be both read and modified like Python classes. Visit RunArgs for more information.","There's also a conversion method provided for transforming a PyRunArgs instance to a RunArgs instance mainly used internally within the rust python bindings.","tolerance: This is an instance of the Tolerance enum, which defines the acceptable range of values for the snark computation."]},{"l":"table","p":["Description","For more information refer to Table","Parameters model (required): This is a string representing the file path of the ONNX model to be loaded.","py_run_args (optional): This is an instance of PyRunArgs struct. If not provided, a new instance of PyRunArgs with default parameters will be created.","Returns The function returns the table formatted as a string in Python. It may throw an IOError if there are issues loading the model file.","Example The following is a Python example of how you might call this function:"]},{"l":"gen_srs","p":["Description For more information refer to GenSRS","Parameters","params_path (required): This is a string representing the file path where the generated SRS will be saved.","logrows (required): This is an integer that represents the K value used in the SRS. More complex models will require more logrows in general. The downside of having more logrows is that the compute resources required will increase, increasing the time taken to generate proofs.","ezkl allows for the overflow of columns which would allow for more complex models to be computer with lesser logrows.","Returns The function returns nothing. Should it be successful a SRS file will be generated at the specified path.","Example","The following is a Python example of how you might call this function:"]},{"l":"gen-witness","p":["Description","For more information refer to Generate Witness","Parameters","data (required): A string representing the file path of the data to be processed.","model (required): A string representing the file path of the model to be used for the forward pass operation.","output (required): A string representing the file path where the result of the forward pass operation will be saved.","py_run_args (optional): This is an instance of PyRunArgs struct. If not provided, a new instance of PyRunArgs with default parameters will be created.","Returns","The function returns nothing, but creates the output file at the provided output path. If there are errors reading and writing to files IOError will be raised.","Example The following is a Python example of how you might call this function:"]},{"l":"mock","p":["Description","For more information visit Mock","Parameters data (required): A string representing the file path of the data to be used in the mock prover.","model (required): A string representing the file path of the model to be used by the mock prover.","py_run_args (optional): This is an instance of the PyRunArgs struct. If not provided, a new instance of PyRunArgs with default parameters will be created.","Returns","The function returns a boolean value. On successful execution, True or False if it does not. It may return an IOError if there are problems reading and writing to files, or a RuntimeError if there are problems constructing the circuit.","Example The following is a Python example of how you might call this function:"]},{"l":"setup","p":["Description","For more information visit Setup","Parameters","model (required): A string representing the file path of the ONNX model to be processed and used to build the circuit.","vk_path (required): A string representing the file path where the verifier key will be saved.","pk_path (required): A string representing the file path where the prover key will be saved.","params_path (required): A string representing the file path where the parameters for the prover will be loaded from.","circuit_params_path (required): A string representing the file path where the circuit parameters will be saved.","py_run_args (optional): This is an instance of the PyRunArgs struct. If not provided, a new instance of PyRunArgs with default parameters will be created.","Returns","The function returns a boolean. If all the operations are successful, it will return True. If an error occurs at any stage, it will throw an IOError for errors associated with reading and writing or a RuntimeError associated with failure in the circuit setup.","Example","The following is a Python example of how you might call this function:"]},{"l":"prove","p":["Description","For more information visit Prove","Parameters","data (required): A string representing the file path of the data to be used in the proof.","model (required): A string representing the file path of the ONNX model.","pk_path (required): A string representing the file path where the prover key will be loaded from.","proof_path (required): A string representing the file path where the proof will be saved.","params_path (required): A string representing the file path where the parameters for the prover will be loaded from.","transcript (required): A string representing the type of transcript to be used. blake, poseidon, or evm is supported.","strategy (required): A string representing the strategy to be used for creating the proof. single or accum is supported.","circuit_params_path (required): A string representing the file path where the circuit parameters will be loaded from.","Returns","The function returns a boolean. If all the operations are successful, it will return True. If an error occurs at any stage, it will throw an IOError for errors associated with reading and writing or a RuntimeError associated with failure in the circuit creation.","Example"]},{"l":"verify","p":["Description","For more information visit Verify","Parameters","proof_path (required): A string representing the file path where the proof will be loaded from.","circuit_params_path (required): A string representing the file path where the circuit parameters will be loaded from.","vk_path (required): A string representing the file path where the verifier key will be loaded from.","params_path (required): A string representing the file path where the parameters for the verifier will be loaded from.","Returns","The function returns a boolean. If all the operations are successful, it will return True. If an error occurs at any stage, it will throw an IOError for errors associated with reading and writing or a RuntimeError associated with failure in the circuit creation.","Example"]},{"l":"aggregate","p":["Description","For more information visit Aggregate","Parameters","proof_path (required): A string representing the file path where the aggregated proof will be saved.","aggregation_snarks (required): A list of strings representing the file paths where the proofs to be aggregated will be loaded from.","circuit_params_paths (required): A list of strings representing the file paths where the circuit parameters will be loaded from.","aggregation_vk_paths (required): A list of strings representing the file paths where the verifier keys will be loaded from.","vk_path (required): A string representing the file path where the aggregated verifier key will be saved.","params_path (required): A string representing the file path where the parameters for the prover will be loaded from.","transcript (required): A string representing the type of transcript to be used. blake, poseidon, or evm is supported.","logrows (required): An integer specifying the number of logrows available for compute, this will need to correspond to the logrows with the params_path.","check_mode (required): A string indicating whether checks will be performed. safe or unsafe is supported. If safety is not required in the case of development you may use unsafe which can provide some speedup.","Returns","The function returns a boolean. If all the operations are successful, it will return True. If an error occurs at any stage, it will throw an IOError for errors associated with reading and writing or a RuntimeError associated with failure in the circuit creation.","Example"]},{"l":"verify_aggr","p":["Description","For more information visit VerifyAggr","Parameters","proof_path (required): A string representing the file path where the aggregated proof will be loaded from.","vk_path (required): A string representing the file path where the verifier key will be loaded from.","params_path (required): A string representing the file path where the parameters for the verifier will be loaded from.","logrows (required): An integer specifying the number of logrows used for computation.","Returns","If the verification of the proof is successful, it will return True. If the proof cannot be verified or an error occurs at any stage, it will return False. If an error occurs at any stage, it will throw an IOError for errors associated with reading and writing or a RuntimeError associated with failure in the circuit creation.","Example"]},{"l":"create_evm_verifier","p":["Description","The create_evm_verifier function is used to generate an Ethereum Virtual Machine (EVM) compatible verifier. This function requires that the Solidity compiler (solc) is installed in the user's environment. You should use solc-select or svm-rs to help manage solc installed in the user's environment.","It first loads the model circuit parameters, the verifier parameters, and the verifier key. Using these, it generates the EVM compatible verifier. The verifier code is then saved as Yul and/or Solidity code.","More information can be found in Verifying On Chain.","Parameters","vk_path (required): A string representing the file path where the verifier key will be loaded from.","params_path (required): A string representing the file path where the parameters for the verifier will be loaded from.","circuit_params_path (required): A string representing the file path where the circuit parameters will be loaded from.","deployment_code_path (required): A string representing the file path where the yul deployment code for the verifier will be saved.","sol_code_path (optional): A string representing the file path where the Solidity code for the verifier will be saved.","Returns","If the EVM compatible verifier is successfully generated and saved, it will return True. If an error occurs at any stage, it will return an IOError or RuntimeError.","Example"]},{"l":"verify_evm","p":["Description","The verify_evm function verifies an Ethereum Virtual Machine (EVM) compatible proof. The function requires the Solidity compiler (solc) to be installed in the user's environment. The proof is loaded, and the deployment code is loaded from the given path. The proof is then verified using the EVM and optionally verified using Solidity if a path to the Solidity code is provided.","More information can be found in Verifying On Chain.","Parameters","proof_path (required): A string representing the file path where the proof will be loaded from.","deployment_code_path (required): A string representing the file path where the deployment code will be loaded from.","sol_code_path (optional): A string representing the file path where the Solidity code will be loaded from. If provided, the proof will also be verified using this Solidity code.","runs (optional): An integer > representing the number of times to run the Solidity verifier. This is only used if sol_code_path is provided.","Returns","If the EVM compatible proof is successfully verified, it will return True. If an error occurs at any stage, it will return an Err variant containing the Python error PyErr. If an error occurs at any stage, it will return an IOError or RuntimeError.","Example"]},{"l":"create_evm_verifier_aggr","p":["Description","The create_evm_verifier_aggr function creates an EVM compatible aggregate verifier. The function requires the Solidity compiler (solc) to be installed in the user's environment. The function loads the parameters and verifier key and generates the aggregate verifier. The generated verifier is then saved as Yul code, and optionally as Solidity code if a path to save the Solidity code is provided.","More information can be found in Verifying On Chain.","Parameters vk_path (required): A string representing the file path where the verifier key will be loaded from.","params_path (required): A string representing the file path where the parameters for the verifier will be loaded from.","deployment_code_path (required): A string representing the file path where the Yul deployment code for the verifier will be saved.","sol_code_path (optional): A string representing the file path where the Solidity code for the verifier will be saved.","Returns","The function returns a boolean. If the EVM compatible aggregate verifier is successfully created and saved, it will return True. If an error occurs at any stage, it will return a IOError or RuntimeError.","Example"]},{"l":"print_proof_hex","p":["Description","The print_proof_hex function loads a proof from a given file path and returns a string containing the hexadecimal representation of the proof.","Parameters","proof_path (required): A string representing the file path where the proof will be loaded from.","Returns","If the proof is successfully loaded and converted to a hexadecimal string, it will return a hex string in Python."]}],[{"l":"Library"},{"l":"Talks to watch","p":["Dante and Jason - Zero-Knowledge Machine Learning with EZKL in Autonomous Worlds","Jason Morton - What Is Unlocked by Practical Zero-Knowledge Proofs? | EDCON 2023 Montenegro","Zuzalu ZKML 101 and panel.","Empower - coming soon","ETH Denver talks - coming soon","Jason Morton - Zero-Knowledge Machine Learning 6 Jan 2023 | ZK SYMPOSIUM","Jason Morton - Zero-Knowledge Machine Learning 16 Nov 2022 | ZkProof Tel Aviv","Jason Morton - Zero-Knowledge Machine Learning 15 Sep 2022 | DEVCON Bogota","Jason Morton - Zero-Knowledge Machine Learning | Stanford Science of Blockchain Conference 2 Sept 2022"]},{"l":"Blog posts","p":["Constraint efficiency","Snarking a GPT"]},{"l":"EZKL in the press and blogs","p":["Spectral Finance: The State of Zero-Knowledge Machine Learning (zkML), 6 June 2023","Fortune: A brief history of zero-knowledge proofs, the buzzy mathematical technique thatâ€™s taken crypto by storm, 5 June 2023","1kx: zkML: Evolving the Intelligence of Smart Contracts Through Zero-Knowledge Cryptography, 23 May 2023","Fortune, 4 May 2023","a16z: Checks and balances: Machine learning and zero-knowledge proofs, 5 Apr 2023","SevenX Ventures: Balancing the Power of AI/ML: The Role of ZK and Blockchain","Coincu: ZKML: Breakthrough Technology With Growth Potential In Security Application","Worldcoin: An introduction to zero-knowledge machine learning (ZKML) 22 Feb 2023"]}],[{"l":"Security","p":["Zero knowledge machine learning, particularly in blockchain applications, is still a nascent field and should be used with caution. Because there have not yet been many production-ready projects, the potential attack vectors include both the usual and the mostly theoretical or unknown. ezkl has not been audited and we make no guarantees on its security.","Moreover, zkml is just one component of an overall cryptosystem, and that system as a whole has to be carefully thought out. Neural networks are not by themselves adequate hash functions; the whole point is that they are susceptible to differentiation!","Here are a few more things to worry about."]},{"i":"aiml-security","l":"AI/ML Security","p":["There are several types of adversarial attacks on neural networks. Gaussian Noise Injection, Data poisoning, Membership Inference Attacks(MIAs), and more are attack vectors that adversaries can use to corrupt your outputs. MIAs and others like it are especially hazardous when the aim of using zkml is to keep the model and its training data private.","Adversarial Training involves training your model with adversarial data so that edge cases are expected and accounted for. CleverHans is a useful tool for discovering potential vulnerabilities in your model. For best security results, have an idea of the overall threat model of your neural net and its potential inputs."]},{"l":"ZK Security","p":["The goal of zero knowledge proof systems is to construct complete, sound proofs. Completeness is the highly probable assurance that any valid proof will verify. Soundness is the quality of the verifier (or parties representing the verifier) knowing that if a proof passes, it is more than likely a true statement. In some cases, such as those in underconstrained circuits, bad proofs can be generated that fool the verifier into passing a false statement. In this case, the vulnerability is not in the machine learning model itself, but in the SNARK constructed by ezkl.","ezkl is a compiler, so eventually should be less susceptible to such issues than a hand-written circuit, but it is still under active development.","Please reach out directly to let us know of any soundess issues you encounter."]},{"l":"Fuzzing","p":["ezkl supports fuzzing over your model's edge inputs to test for potential vulnerabilities. Use your input.json and network.onnx files to run:","Be sure to replace num-runs with the amount of fuzz testing rounds you want to do along with other parameters you are using to generate your circuit.","Thank you for using ezkl; please contact us if you have any comments on this documentation."]}],[{"l":"FAQ"},{"i":"what-programming-languages-and-frameworks-does-ezkl-support","l":"What programming languages and frameworks does ezkl support?","p":["ezkl is a command line tool, and a library that can be used from Rust or Python. You may want to use Python to create a neural network and export it. Though ezkl is built with Rust, you do not need to use Rust except possibly for installation."]},{"i":"do-i-need-to-know-rust-before-getting-started-with-ezkl","l":"Do I need to know Rust before getting started with ezkl?","p":["No, Rust is not a requirement to use the library. As long as you have the ONNX file and proper input & output format of the model, you can use ezkl."]},{"l":"Technical"},{"i":"why-is-the-gen-srs-step-slow","l":"Why is the gen-srs step slow?","p":["Generating a structured reference string takes a considerable amount of time and memory. Make sure your machine has enough memory available and wait for the process to finish. Alternatively, download a pre-generated srs."]},{"i":"can-i-use-ezkl-with-other-machine-learning-frameworks-like-tensorflow-pytorch-or-scikit-learn","l":"Can I use ezkl with other machine learning frameworks like TensorFlow, PyTorch, or Scikit-learn?","p":["All ezkl requires is an onnx file and a JSON configuration of mock inputs and outputs of the neural network. At this time, it works best with PyTorch."]},{"i":"how-fast-is-ezkl","l":"How fast is ezkl?","p":["We believe that ezkl is the fastest zkml package available, and we are working hard every day to make it faster. Feel free to run cargo bench on your machine to see what the benchmarks are for your hardware."]},{"i":"do-i-need-to-deploy-a-verifier-smart-contract-to-use-ezkl","l":"Do I need to deploy a verifier smart contract to use ezkl?","p":["No, we recently integrated a WASM verifier that you can use to verify proofs from your web application. You can also use the EVM verifier to verify proofs locally, or the command line ezkl verify command."]},{"l":"Errors"},{"i":"error-verifyerror","l":"Error: VerifyError","p":["A VerifyError is thrown when the Mock prover fails, often due to a mismatched shape problem in the model. Please verify that your input.json inputs and outputs match those of your .onnx file."]},{"i":"error-dimmismatch","l":"Error: DimMismatch","p":["A DimMismatch error is thrown when there is a mismatch in the lengths of the tensor operands during circuit construction."]},{"i":"error-lookupinstantiation","l":"Error: LookupInstantiation","p":["This error is thrown when there is an error during the creation of a lookup table"]},{"i":"error-tablealreadyassigned","l":"Error: TableAlreadyAssigned","p":["A TableAlreadyAssigned Error is thrown when ezkl attempts to initialize a lookup table that has already been initialized"]},{"i":"error-unsupportedop","l":"Error: UnsupportedOp","p":["An UnsupportedOp Error is thrown when there is an operation in the ONNX file that ezkl cannot yet handle. Please look at the supported operations under src/circuit/ops to get an idea of what operations ezkl can handle."]},{"i":"error-pyvalueerror","l":"Error: PyValueError","p":["This is a pyo3 error that occurs when a data type fails to be extracted from Python to Rust. Please make sure you are passing the correct data types when utilizing the python bindings."]},{"i":"error-invalidlookupinputs","l":"Error: InvalidLookupInputs","p":["InvalidLookupInputs is thrown when the wrong inputs were passed to a lookup node."]},{"i":"error-invaliddims","l":"Error: InvalidDims","p":["InvalidDims is thrown when there is a shape mismatch in circuit construction. Invalid dimensions were used for a node with the given index and description."]},{"i":"error-wrongmethod","l":"Error: WrongMethod","p":["This error means that the wrong method was called to configure a node with the given index and description"]},{"i":"error-missingnode","l":"Error: MissingNode","p":["MissingNode is thrown when a requested node is missing in the graph with the given index"]},{"i":"error-opmismatch","l":"Error: OpMismatch","p":["OpMismatch is thrown when an unsupported method was called on a node with the given index and description"]},{"i":"error-unsupportedop-1","l":"Error: UnsupportedOp","p":["UnsupportedOp is thrown when there is an operation in the onnx graph that isn't supported by ezkl"]},{"i":"error-missingparams","l":"Error: MissingParams","p":["MissingParams is thrown when a node has missing parameters; please check the parameters in your model's operations"]},{"i":"error-misformedparams","l":"Error: MisformedParams","p":["MisformedParams is thrown when a node has misformed parameters; the error can stem from erroneous padding height and width dimensions, wrong kernel / data format, dilations that are not uint type, and more."]},{"i":"error-visibility","l":"Error: Visibility","p":["This error is typically thrown when no public variables are passed to the circuit configuration function"]},{"i":"error-nonconstantdiv","l":"Error: NonConstantDiv","p":["ezkl only supports divisions by constants"]},{"i":"error-nonconstantpower","l":"Error: NonConstantPower","p":["ezkl only supports constant exponents"]},{"i":"error-rescalingerror","l":"Error: RescalingError","p":["This error is thrown when attempting to rescale inputs for an operation"]},{"i":"error-modelload","l":"Error: ModelLoad","p":["This error is thrown when a model fails to load; please check your onnx file for missing connections / unsupported layers. We suggest using Netron to view onnx files."]}],[{"l":"Overview"},{"i":"building-a-voice-emotion-classifier-and-verifier-with-pytorch-ezkl-and-ethereum-smart-contracts","l":"Building a Voice Emotion Classifier and Verifier with PyTorch, EZKL, and Ethereum Smart Contracts","p":["This is part 1 of our tutorial on building the Cryptoidol demo app. The finished app is on Github; check out the backend and frontend."]},{"l":"Background Knowledge","p":["This article assumes prior rudimentary knowledge on the EVM, PyTorch and zero knowledge proof cryptography. If you are unfamiliar with one, a few or all of these technologies/methods (or you just want a refresher), check out the linked articles as needed."]},{"l":"Introduction","p":["In this tutorial, we will demonstrate an end-to-end flow of training a model for a specific task, creating a proof of judgement, deploying an EVM verifier, and verifying the proof of judgement using the verifier. Specifically, our task is to build a classifier that can judge voices based on their emotional content.","The voice datasets we will use are labeled using the same emotion and tone labeling standard and consist of 8 emotions: neutral, calm, happy, sad, angry, fear, disgust, surprise. The datasets are obtained from Kaggle and include the TESS, RAVDESS SONG, RAVDESS SPEECH, CREMA, and SAVEE datasets.","The code and instructions in this tutorial are provided in a Jupyter notebook which can be run in a Python environment with the necessary libraries installed."]},{"l":"Data Preparation","p":["First, we download the datasets using the Kaggle CLI and store them in a directory specified by the VOICE_DATA_DIR environment variable. We then load the datasets and create a pandas DataFrame for each. Each DataFrame includes two columns: 'Emotions', which is the label, and 'Files', which is the path to the audio file.","After loading all the datasets, we concatenate them into one DataFrame, which we will use for training our model. We also plot the distribution of emotions in our dataset using seaborn to visualize the data."]},{"l":"Training","p":["We will train a Convolutional Neural Network (CNN) model using PyTorch to classify the voice data. We choose a CNN model because we will convert all audio files into 2D frequency-domain spectrograms, which CNNs are well-suited to handle.","Our model is defined with a Conv2d layer followed by a ReLU activation function and a Linear layer. We then train the model using the Adam optimizer with a learning rate of 0.001 and a weight decay of 0.001 for regularization. We use Mean Squared Error as the loss function.","The model is trained for 10 epochs with a batch size of 10. We also split the data into training, validation, and test sets with 80%, 10%, and 10% of the data, respectively. After each epoch, we compute the validation loss to monitor the model's performance on unseen data."]},{"l":"Exporting and Verifying the Model","p":["After training the model, we export it to the ONNX format, which is a platform-agnostic format for machine learning models. We also save a sample input to a JSON file for later use.","Next, we generate a settings file for our model using the gen_settings and calibrate_settings functions from the EZKL library. We also download a Structured Reference String (SRS) which is needed for generating Zero Knowledge Proofs (ZKPs).","We then generate a witness for our model, which are the model outputs when feeding the previously saved input through the model. After that, we run a mock proof to check that all the constraints are valid.","Next, we set up the proving and verifying keys for our model and generate a full proof. We then verify the proof as a sanity check."]},{"l":"Deploying and Verifying the EVM Verifier","p":["Finally, we create an Ethereum Smart Contract that acts as a verifier for our model. We deploy the contract to a local Ethereum node using the Anvil Ethereum node simulator. After deploying the contract, we obtain its address which we will use to interact with it.","We then verify the proof using the deployed contract by calling the verify_evm function from the EZKL library and passing the proof and the contract's address. If everything is set up correctly, the proof should be verified successfully."]},{"l":"Conclusion","p":["We hope this tutorial provides a foundation for building more complex production-ready application on EZKL that require secure, verifiable judgments."]}],[{"l":"Idol Model Tutorial","p":["This is part 2 of our tutorial on building the Cryptoidol demo app; check out the backend and frontend."]},{"l":"Background Knowledge","p":["Check out these links for some useful knowledge on:","EVM,","PyTorch, and","zero knowledge proof cryptography."]},{"l":"Voice data","p":["The voice datasets we will use are labeled using the same emotion and tone labeling standard and consist of 8 emotions: neutral, calm, happy, sad, angry, fear, disgust, surprise. The datasets are obtained from Kaggle and include the TESS, RAVDESS SONG, RAVDESS SPEECH, CREMA, and SAVEE datasets.","Here we showcase a full-end-to-end flow of:","training a model for a specific task (judging voices)","creating a proof of judgment","creating and deploying an evm verifier","verifying the proof of judgment using the verifier","First we download a few voice related datasets from kaggle, which are all labelled using the same emotion and tone labelling standard.","We have 8 emotions in both speaking and singing datasets: neutral, calm, happy, sad, angry, fear, disgust, surprise.","To download the dataset make sure you have the kaggle cli installed in your local env pip install kaggle. Make sure you set up your kaggle.json file as detailed here. Then run the associated voice_data.sh data download script: sh voice_data.sh","Make sure you set the VOICE_DATA_DIR variables to point to the directory the voice_data.sh script has downloaded to. This script also accepts an argument to download to a specific directory: sh voice_data.sh /path/to/voice/data."]},{"l":"Training","p":["During training we convert all audio files into 2D frequency-domain spectrograms so that we can leverage convolutional neural networks, which tend to be more efficient than time-series model like RNNs or LSTMs. We thus:","Extract the mel spectrogram from each of the audio recordings.","Rescale each of these to the decibel (DB) scale.","Define the model as the following model:(x) - (conv) - (relu) - (linear) - (y)","You may notice that we introduce a second computational graph (key) - (key). The reasons for this are to prevent someone else from stealing your submission, and if you are not interested you can skip the following paragraph."]},{"l":"MEV prevention","p":["Let's say that obtaining a high score from the judge and then submitting said score to the EVM verifier could result in the issuance of a reward (financial or otherwise). There is an incentive then for MEV bots to scalp any issued valid proof and submit a duplicate transaction with the same proof to the verifier contract in the hopes of obtaining the reward before the original issuer. Here we add (key) - (key) such that the transaction creator's public key / address is both a private input AND a public input to the proof. As such the on-chain verification only succeeds if the key passed in during proof time is also passed in as a public input to the contract. The reward issued by the contract can then be irrevocably tied to that key such that even if the proof is submitted by another actor, the reward would STILL go to the original singer / transaction issuer.","We leverage the often-used Adam optimizer, coupled with 0.001 weight decay so as to regularize the model. The weight decay (a.k.a L2 regularization) can also help on the zk-circuit end of things in that it prevents inputs to Halo2 lookup tables from falling out of range (lookup tables are how we represent non-linearities like ReLU and Sigmoid inside our circuits).","To encode the judgeâ€™s â€œpreferencesâ€, we convert labels to a number between 0 and 1 where 1 is pleasantly surprised and 0 is disgust and the rest are floats in between. The model loves pleasantly surprised voices and hates disgust ;) ."]},{"l":"Exporting and Verifying the Model","p":["After training the model, we export it to the ONNX format, which is a platform-agnostic format for machine learning models. We also save a sample input to a JSON file for later use.","Next, we generate a settings file for our model using the gen_settings and calibrate_settings functions from the EZKL library. This settings file basically instantiates a bunch of parameters that determine the circuit shape, size . We use recommend also running calibrate_settings because of the way we represent nonlinearities in the circuit (using Halo2's lookup tables), it is often best to calibrate this settings file as some data can fall out of range of these lookups.","As we use Halo2 with KZG-commitments we need an SRS string from (preferably) a multi-party trusted setup ceremony. For an overview of the procedures for such a ceremony check out this page. The get_srs command retrieves a correctly sized SRS given the calibrated settings file from here.","We then generate a witness for our model, which are the model outputs when feeding the previously saved input through the model. After that, we run a mock proof to check that all the constraints are valid.","Next, we set up the proving and verifying keys for our model and generate a full proof. We then verify the proof as a sanity check.","Deploying and Verifying the EVM Verifier","Finally, we create an Ethereum Smart Contract that acts as a verifier for our model. We deploy the contract (using deploy-verifier) to a local Ethereum node using the Anvil Ethereum node simulator running on port 3030. In a separate terminal window (or using the notebook bash tooling !) run anvil -p 3030 to start the node.","After deploying the contract, we obtain its address which we will use to interact with and we can then verify the proof using the deployed contract by calling the verify_evm function from the EZKL library and passing the proof and the contract's address. If everything is set up correctly, the proof should be verified successfully!"]}],[{"l":"Idol Backend Tutorial","p":["This is part 3 of our tutorial on building the Cryptoidol demo app; check out the backend and frontend.","Setting up the proving server is very involved. Perhaps you have better things to do and would prefer a hosted service that computes proofs for your application. We now offer a managed service, ezkl hub, which takes care of all this work.","Click here to join the waiting list and try out ezkl hub."]},{"l":"Overview","p":["So you have trained the model and obtained the public key and verifier key. Thereâ€™s a new problem: how are you going to serve the proofs to your users?","To do this we need a server. There are a number of ways to build a server. In this tutorial we will leverage the python bindings and use the Flask web framework because it is quick and easy to use. Weâ€™ve found that many teams using ezkl end up building their own proof server, so we decided to make a simple one part of a tutorial repo to save you time."]},{"l":"Step 1. Setting up the Flask App","p":["We are going to use poetry https://python-poetry.org/ as a way of managing our packages. If you are already familiar with npm and yarn, poetry is the equivalent in python. It has the added benefit of resolving package dependencies which ensures that you have all the compatible versions needed.","First, install poetry https://python-poetry.org/docs/. After you install poetry you can simply run","This will setup a poetry environment in the root of your repository. Follow the setup instructions provided. You can skip the dependency setup in the poetry init script for now. We will use the add command instead to install the dependencies.","There may be a need to install other system dependencies. So if the install fails, try running the following (if you are on a Debian system).","In the root of your repository, create a [app.py](http://app.py) file to set up the initial server. Weâ€™re going to keep things simple here and not use blueprints. The backend is mostly going to be a REST API server. Create a test server as such.","Access the poetry virtual environment by calling","After which you may then start the server by calling","In your browser you should be able to see the index endpoint when you navigate to the localhost: endpoint where your server is being served if you have successfully created the server.","Screenshot","Congratulations! You have just set up a basic Flask server."]},{"i":"step-2-setting-up-celery","l":"Step 2: Setting up Celery","p":["Now we need a way of proving things without blocking the server. While it is possible to use asynchronous python to achieve this, it might be better to delegate the proofs to another process entirely. One way of achieving this is with a job queue and worker processes that can pick up jobs from that job queue. The Python ecosystem has Celery which does this well.","For Celery to work, we will need Redis and RabbitMQ, Redis is a key-value database to pass results to and from various worker processes. RabbitMQ is the message passing service for the job queue. Now append to the existing app.py with the following","Now, if you try to start the server it should fail. This is because the various environment values are not set up. While you can manually run redis and rabbitmq locally, itâ€™s much simpler to use docker for this. We will use docker compose to orchestrate this. Install docker first.","In the root of the repo, create a docker-compose.yaml file and add in the following.","We will create 4 services, web hosts the python server and serves the app via gunicorn. redis runs the redis key-value database for results, rabbitmq will be the message passing service for the queue, and worker is the celery worker that will compute proofs.","Setup a new Dockerfile in the root of the repository containing the following.","Now with that setup you should be able to build and run the server with the following commands","If it is working you should be able to navigate to your browser at 0.0.0.0:8000 now and view the default message. If not something is wrong and we will need to debug it!"]},{"i":"step-3-setting-up-the-proving-service","l":"Step 3: Setting up the proving service","p":["Now with celery setup we can create an endpoint to receive proofs. We will also need all the various artifacts. Append the following to app.py","Once this is setup you may want to restart the docker containers just to be doubly sure that new code is running.","If everything is working properly, record an audio sample of yourself or find any audio file and use the following curl command to double check if the prove endpoint is working. For example:","If the prover is working nicely you should receive the output_data and proof."]},{"i":"step-4-serving-in-production","l":"Step 4: Serving in Production","p":["You will want to secure the redis and rabbitmq by setting up credentials for them and the modifying the environment variables for them.","See the following tutorial for redis: https://nickjanetakis.com/blog/docker-tip-27-setting-a-password-on-redis-without-a-custom-config","See the following tutorial for rabbitmq: https://cloudinfrastructureservices.co.uk/create-rabbitmq-docker-container-image/","The setup will differ depending on the threat vectors, cloud providers, and how you would like to secure the backend.","We will also need ssl certificates, to do this we need an additional certbot and nginx service.","Append the following in the docker-compose.yaml file:","Now create a ./nginx folder in the root of your repository. We will create two files ./nginx/Dockerfile and ./nginx/nginx.conf. In the Dockerfile we just need to remove the default.conf nginx file to replace with our own.","Then in the ./nginx/nginx.conf we need to specify how the reverse proxy should work.","Important! You will need a domain for the ssl to work. You may purchase it from services like namecheap, google domains, godaddy, so on. You will also need to obtain a Debian or Ubuntu box to host the server.","In the ./nginx/nginx.conf add the following","You will now want to upload the entire repo to a Debian machine to host the server. You may do this with ftp or creating a git repo and cloning the repo into the server. Now in the server, run the same docker compose functions to set things up.","Check if your 443 and 80 ports are exposed via your DNS provider. We will need them exposed for the certbot challenge to obtain ssl certificates for your server. Copy the following script into your server to setup the challenge. Change the domains to the ones you have. This script was provided by this repo https://github.com/wmnnd/nginx-certbot/blob/master/init-letsencrypt.sh. You may want to set staging to 1 to perform a dry run, repeatedly spamming the script to debug can cause rate limits to be hit.","If the setup ran correctly you should now have certbot serving ssl certificates on your server. You should be able to go to your domain at [https://backend.myserver.com](https://backend.myserver.com) and see the same success message and also run proofs on [https://backend.myserver.com/prove](https://backend.myserver.com/prove)"]},{"l":"Conclusions and ezkl Hub","p":["If you have gone through all these steps you should now have a live server that is able to serve proofs!","Setting up the proving server is very involved. Perhaps you have better things to do and would prefer a hosted service that computes proofs for your application. We now offer a managed service, ezkl hub, which takes care of all this work.","Click here to join the waiting list and try out ezkl hub."]}],[{"l":"Idol Contracts Tutorial","p":["This is part 4 of our tutorial on building the Cryptoidol demo app; check out the backend and frontend.","The crypto idol contract stores the score of contestants and makes calls to the on-chain evm verifier of the corresponding ai model used to judge contestants to validate the submitted scores."]},{"i":"step-1-write-cryptoidolsol","l":"Step 1. Write CryptoIdol.sol","p":["Verifier Contract Interface: The contract leverages an external Verifier contract to verify the proof submitted by contestants. The Verifier contract interface has one function - verify- which takes public inputs and a proof as parameters and returns a boolean indicating whether the proof is valid.","Contestant Struct: The Contestant struct keeps track of a participant's score and the cycle in which they participated. A mapping associates an address (the contestant's Ethereum address) with another mapping of uint256 (the contestants entry number) to Contestant. The number of entries a given contestant has done is store in the contestantsCount mapping.","Admin: The contract has an admin address, responsible for updating the Verifier contract when a new cycle occurs. Only the admin can perform this operation. We set the admin account to the EZKL teamâ€™s multisig wallet.","Cycle: This represents the current cycle of the competition. The cycle number is incremented whenever the admin updates the Verifier contract.","3. Events","NewEntry: This event is emitted when a contestant submits their score. It logs the contestant's address, the count of their submissions, their score, and the cycle number. These events are indexed on the client-side to construct the leaderboard.","NewCycle: This event is emitted when the admin updates the Verifier contract, signalling the start of a new cycle. It logs the new Verifier's address and the updated cycle number.","4. Functions","updateVerifier: This function is used by the admin to update the Verifier contract. It increments the cycle number and emits a NewCycle event.","submitScore: Contestants use this function to submit their score and a proof. The function verifies the proof using the current Verifier contract, updates the contestant's score, and emits a NewEntry event.","5. Protection Against Miner Extractable Value (MEV)","In order to guard against MEV, the contract design includes a critical feature: the address of the account submitting their score is both a private and a public input to the proof.","Let's consider a scenario where a high score from the judge could result in a reward. There would then be an incentive for MEV bots to duplicate any issued valid proof and submit the transaction to the verifier contract, attempting to claim the reward before the original issuer.","However, with the transaction creator's public key/address being a private input AND a public input to the proof, the on-chain verification will only succeed if the key passed in during proof creation is also passed in as a public input to the contract. This design ensures that the reward issued by the contract is irrevocably tied to the original contestant's key. So even if the proof is submitted by another actor, the reward would STILL go to the original contestant, thus providing a safeguard against MEV."]},{"l":"Step 2. Deploy the contracts","p":["1. Adjust compiler settings.","As you prepare to deploy the verifier and crypto idol contracts, it is critical to set the Ethereum Virtual Machine (EVM) version to a configuration that's compatible with layer 2 blockchains. In our experience, the 'London' version has shown to be the most compatible. For the purpose of this tutorial, we'll use Remix as our deployment platform. To modify the EVM version to 'London', navigate to the 'Advanced Configurations' tab and select 'London' from the 'EVM Version' dropdown list. Neglecting to make this adjustment might result in unsuccessful deployment of your verifier Solidity code, often manifesting as a 'push0 not a valid opcode' error.","Also in cases when you are deploying an especially large verifiers and want to save on deployment costs (or just get the verifier below the max contract size limit of 24.5 kb), you will need to enable optimizations by setting the runs param to 1 to maximize deployment costs savings.","2. Deployment","You should deploy the verifier contract first, as we will need to pass the address of the verifier to the crypto idol contractâ€™s constructor. Click the page icon next to â€˜xâ€™ on the deployed verifier instance to copy its address, then paste it into the _ verifier deploy param of CryptoIdol.sol. For the _ admin field, paste in whatever account address you want to have the ability to update the verifier contract that the crypto idol contract connects to."]},{"l":"Step 3. Create a Subgraph for the Leaderboard","p":["Creating a subgraph enables the development of a GraphQL endpoint to query the \"NewEntry\" events emitted by the contract. This data forms the basis of the CryptoIdol leaderboard, displaying the contestants with the highest submitted scores for a given cycle. By using this method, we can avoid storing the complete leaderboard on the blockchain, significantly reducing storage requirements and ensuring efficient data access."]},{"l":"Set up a Subgraph","p":["Follow these steps to create a subgraph:","Initialize a New Subgraph: Initialize a new subgraph on The Graph's hosted service. Ensure you have the Graph CLI installed and use the command graph init to start a new subgraph.","Define the Schema: Define a GraphQL schema for your subgraph. Your schema should at least include the \"NewEntry\" events, with fields for score, contestant, and cycle.","Create a Mapping: The mapping script processes the event data from the blockchain and converts it into the format defined by your schema. It's written in AssemblyScript, a variant of TypeScript. For the \"NewEntry\" event, you will need to map the score, contestant, and cycle fields.","Deploy the Subgraph: Deploy the subgraph to The Graph's hosted service using the graph deploy command."]},{"l":"Query the Subgraph","p":["Here is a sample TypeScript script that uses the created subgraph to render the leaderboard data:","This script sends a GraphQL request to the subgraph and retrieves the \"NewEntry\" events for a specific cycle. It then processes this data to generate a leaderboard, which it sorts in descending order by score."]}],[{"l":"WASM Tutorial","p":["wasm whirlwind"]},{"l":"Getting Started","p":[".gitignore","After this step, make sure you have access to the PATH for both clang and llvm. We'll be using environment variables such as CC=/opt/homebrew/opt/llvm/bin/clang for the remainder of the project.","Another thing we need before we get our .wasm file is LLVM. LLVM is a compiler tool that will help us use libraries that are essential for compiling our Rust ezkl code to a WASM binary fit for wasm32-unknown-unknown. You can get the latest release here(especially for Windows users) or install it with a package manager:","ezkl_lib_bg.wasm","ezkl_lib_bg.wasm.d.ts","ezkl_lib.d.ts","ezkl_lib.js","First, we need to add the wasm32-unknown-unknown target to our rustup configuration. wasm32-unknown-unknown is is a target for creating WebAssembly binaries. The wasm32 part represents the platform (WASM 32 bit in our case). The first unknown specifies the operating system we are building on. We want to build on any operating system since we're just building on browser. The second unknown refers to the target's standard library (Rust/C++ std), but with WASM, we won't be using one. We add this as a target with:","If something goes wrong, be certain that the paths to your llvm-ar and clang libraries are correct. Also make sure wasm-pack is installed and that your .cargo/config file in ezkl looks like this:","Install wasm-pack","It's useful to have a verifier on a blockchain. However, sometimes you just want to generate and verify proofs in the browser. Thankfully, ezkl supports a WASM environment that you can use to generate proofs and verify them in-browser. For those who are unfamiliar, here is a good resource on WASM and here you can find the functions we define for ezkl's WASM interface. Let's get started!","Linux","Mac","Mac: You can use Homebrew to install llvm. This library comes with clang, which we'll also need.","Make sure that you supply the correct paths for llvm-ar and clang (AR and CC). You can use brew info llvm on Mac or dpkg -L llvm for Linux.","Note that you should be on Rust's nightly release channel when interacting with ezkl.","Now, navigate to your fork or branch of ezkl and install the WASM server runner:","package.json","README.md","Remove the .gitignore file if you want to add pkg to your root git directory.","This command will generate a directory called pkg in our root ezkl directory. Within it, you will find these files:","With this, we're finally able to compile our .wasm file! You can do that with this command:"]},{"l":"Creating a frontend","p":["After this gives us our pk.key file, we will use that along with the input data(.json), the serialized circuit, the serialized circuit parameters, and our commitment scheme paramenters to trigger our prove_wasm function.","And thus, we have a WASM prover and verifier that you can use for your zkml project without having to worry about the blockchain! Feel free to check out the source code and build your own zkml applications with this simple interface. Thank you for reading and thank you for using ezkl.","At the end of the interaction, your screen should look something like:","circuit_params_ser: circuit parameters (circuit file generated from the last step)","circuit_params_ser: circuit parameters (circuit)","circuit_ser: circuit (network.onnx)","copy your new pkg directory into the project","create an index.html and paste this code in:","data: input data (input.json)","Finally, upload the corresponding files to each parameter.","From here, feel free to change the RunArgs as you please to make the best SNARK for your circuit. These are the arguments you see here. After you run the main function with cargo run --bin genscript, you will have a file called run_args.params. You can use this as the second parameter for gen_circuit_params_wasm.","Make a new directory for your project.","Now that we have the wasm-pack package, we can build a simple frontend that uses its exports to prove and verify models (we would love to see projects using this in more intricate ways). Here's what we'll do step-by-step:","params_ser: commitment scheme parameters (x.srs)","pk: proving key (pk.key)","proof_js: proof (network.proof)","Run a simple http server such as python3's:","RunArgs: RunArgs generated earlier in the tutorial","The ordering for Generate Circuit Params is:","The ordering for Generate Proving Key is:","The ordering for Generate Verifying Key is:","The ordering for Prove(from left to right) is:","The ordering for Verify(from left to right) is:","This script generates a simple HTML frontend with fields to pass in files for our input fields (we'll upload them from our ezkl directory). It also calls the ezkl_lib.js folder in our pkg to fetch the exported prove_wasm, verify_wasm, gen_circuit_params_wasm, gen_pk_wasm, and gen_vk_wasm functions.","This will prompt you to download a file called network.proof. network.proof is a binary file of the generated proof. Note that this step may take time. After network.proof has been downloaded, upload the file to the first value of the Verify function.","True or False should appear as the result for the Verify function.","verification","vk: verifier key (vk.key)","We will use the circuit file generated in this step to pass to our gen_pk_wasm function along with our commitment scheme parameters(x.srs) and serialized circuit.","We'll be using the ezkl library to pass in the serialized circuit(.onnx) and runargs to our gen_circuit_params_wasm function. Copy the following into runargs.params:","When the network.proof file is created here, we will pass that along with the verify key and serialized circuit parameters to our verify_wasm function. It is important to note that you will have a lot of this information after you create a circuit with ezkl. Feel free to store them in your project (perhaps .gitignore-ing them). Now that we know what will happen, let's begin with the frontend."]}]]